This Read Me is a little different from normal software in that it concerns cryptography.

Cryptography means hidden writing.

The cryptographer is the writer of hidden writing.

The cryptanalyst analyzes the hidden writing.

Now, having said that there are three cryptographic primitives.

Message Authentication Codes (MAC) are hashes that are used to create a unique number to test that the original message is unchanged.

Stream ciphers are a set of algorithms used to act on a data stream to scramble.

Block ciphers are also a set of algorithms used to act on a block of data to scramble.


Stream ciphers allow a lot of ways for cryptoanalyists to try and guess the key that was used to generate the hidden writing.

Block ciphers on the other hand allow less exploitable information to leak out of the encrypted message.

The issue with block ciphers is that there are various ways to chain the encrypted blocks together (modes) so that when it comes to decryption the randomness from the succeeding block can be used to make the cryptanalyst's job harder.

There are many modes, but many of them are fairly weak and allow cryptanalyist clues as to what the secret key is that was used to encrypted the message.

Some of the modes are called cipher block chaining (CBC), electronic code book (ECB) and outpt feedback (OFB).  These over time have show weaknesses.

Out of what is out now, I prefer Galois Counter Mode (GCM).  It uses Wegman Carter construction to generate a MAC for the randomness between the blocks.  

A word of warning, there is a bit of randomness that must be added before using GCM.  This is called either the initial value, initializing vector or instantiation vector/value (IV).

In the case of GCM it needs to be a nonce (Number Once).  All nonces are IVs, but not all IVs are nonces.  I understand that if you reuse a nonce with GCM it is rather trivial to guess the secret key.

Finally, I will address the actual cipher suite.  I trust AES256.  AES stands for the Advanced Encryption Standard and 256 is the length of the key.  The key will be broken into 14 session keys.  Each session will perform a value subustitution using an S-Box (from 00-ff by 00-ff).  The block will then be separated into four parts that are shifted one block to the left.  Finally, the columns are then mixed.

All of this is done fourteen times except that the last mixing is not done.

While at the RSA Conference in 2018, the of the members of the cryptography panel quipped that he did not believe that AES256 would be broken tomorrow. And, there was nervious laughter from the audiance.

Lastly, having touched on MACs, I would like to state my position based on the reading that I have done that it seems that there is a lot of confidence on poly1305.  I will not contradict that; however, there is a lot of software that does not have that MAC algorithm and in a pinch I would choose SHA3.

SHA2 is based on SHA1 which is based on SHA, so I am concerned with collisions.

Post lastly, some of my thoughts about randomness.  When I was at Sun Microsystems in the Summer of 2000, people were running around with their hair on fire because /dev/random was not random.  Randomness is associated with entropy.  Now /dev/random gets its randomness from the filesystem cache as well as the DNS cache among other resources.  The difference between /dev/random and /dev/urandom is even though they use the same resources, /dev/random will not reuse the value provided by the resource unless it has an updated value.  This is a problem sometimes because /dev/random blocks until a new value is available.  With /dev/urandom not blocking, another issue arises in that the key generated has repeated values; and therefore, can be easily guessed.

To me, repeated values in a key generated by /dev/urandom or os.random in Python are not random and if possible should be avoided especially in the generation of private keys since there is no urgency, and the key maker has time to create a truly random private key...

Remember, in cryptography only the paranoid survive.
